---
title: "Instruction for Text Analysis of Live Tweets"
author: "Based on University of Washington `Introduction to Data Science` Coursera Class Project"
output: html_document
--- 

Twitter represents a fundamentally new instrument to make social measurements. Millions of people voluntarily express opinions across any topic imaginable --- this data source is incredibly valuable for both research and business.
I will show how to:

* access the twitter Application Programming Interface (API) using python
* estimate the public's perception (the sentiment) of a particular term or phrase
* analyze the relationship between location and mood based on a sample of twitter data
* analyze the frequency of the words and hash tags

### Obtaining Twitter Data
The steps below will help you set up your twitter account to be able to access the live 1% stream.

1. Create a twitter account if you do not already have one.
2. Go to <https://dev.twitter.com/apps> and log in with your twitter credentials.
3. Click "Create New App"
4. Fill out the form and agree to the terms. Put in a dummy website if you don't have one you want to use.
5. On the next page, click the "API Keys" tab along the top, then scroll all the way down until you see the section "Your Access Token"
6. Click the button "Create My Access Token". 
7. You will now copy four values into twitterstream.py. These values are your "API Key", your "API secret", your "Access token" and your "Access token secret". All four should now be visible on the API Keys page. (You may see "API Key" referred to as "Consumer key" in some places in the code or on the web; they are synonyms.) Open twitterstream.py and set the variables corresponding to the api key, api secret, access token, and access secret.
8. Run the following and make sure you see data flowing and that no errors occur.
```{r eval=F}
python twitterstream.py > tweets.txt
```
This command pipes the output to a file. Stop the program with Ctrl-C after several minutes. 

9. If you wish, modify the file to use the [twitter search API](https://dev.twitter.com/rest/reference/get/search/tweets) to search for specific terms. For example, to search for the term "microsoft", you can pass the following url to the twitterreq function: <https://api.twitter.com/1.1/search/tweets.json?q=microsoft>.

###Deriving the Sentiment of Each Tweet
We will compute the sentiment of each tweet based on the sentiment scores of the terms in the tweet. The sentiment of a tweet is equivalent to the sum of the sentiment scores for each term in the tweet.


We use `tweet_sentiment.py` which accepts two arguments on the command line: a sentiment file and a tweet file like the one we generated (`tweets.txt`).

```{r eval=F}
python tweet_sentiment.py Sentiment.txt tweets.txt
```

The file `Sentiment.txt` is provided and contains a list of pre-computed sentiment scores. Each line in the file contains a word or phrase followed by a sentiment score. Each word or phrase that is found in a tweet but not found in `Sentiment.txt` will be given a sentiment score of 0. See the file `Sentiment-README.txt` for more information.

Refer to the [twitter documentation](https://dev.twitter.com/overview/api/tweets) to understand more about the data structure you are working with. 

### Which State is the Happiest?
`happiest_state.py` returns the name of the happiest state as a string. 

```{r eval=F}
python happiest_state.py Sentiment.txt tweets.txt
```

We use the user field to determine the twitter user's home city and state. This location does not necessarily correspond to the location where the tweet was posted, but it's reasonable to use it as a proxy.

### Computing Term Frequency
`frequency.py` computes the term frequency histogram of the live stream data.
The frequency of a term can be calculated as [# of occurrences of the term in all tweets]/[# of occurrences of all terms in all tweets]

```{r eval=F}
python frequency.py tweets.txt
```

### Finding Top Ten Hash Tags
`top_ten.py` that computes the ten most frequently occurring hash tags from the collected tweets.
```{r eval=F}
python top_ten.py tweets.txt
```

**Note that you can instead use a subset of all tweets (tweets_10K.txt) for all the analysis** 
